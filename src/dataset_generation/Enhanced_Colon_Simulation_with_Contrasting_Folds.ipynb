{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQXk2FZ3sV32"
   },
   "source": [
    "I've enhanced the colon simulation with several key improvements:\n",
    "\n",
    "Darker Central Area:\n",
    "\n",
    "The colon tube now has a darker center that gradually lightens toward the edges\n",
    "This creates a more realistic depth effect, simulating how light diminishes deeper in the colon\n",
    "\n",
    "\n",
    "More Contrasting Folds:\n",
    "\n",
    "The concentric rings now alternate between lighter and darker shades\n",
    "Fold widths vary randomly within a specified range\n",
    "Added more folds (6 instead of 5) for a more detailed appearance\n",
    "\n",
    "\n",
    "Depth and Perspective Effects:\n",
    "\n",
    "Outer folds are more pronounced with higher opacity\n",
    "The squish factor changes with distance (more circular as we move outward)\n",
    "Added highlight effects on the upper parts of some folds to simulate light reflection\n",
    "\n",
    "\n",
    "Center Simulation:\n",
    "\n",
    "Created a dark central area with a gradient effect\n",
    "This simulates the natural darkness and tunnel-like appearance of the colon lumen\n",
    "\n",
    "\n",
    "\n",
    "These changes will make the synthetic images more realistic and provide better contrast for the polyp detection task. The alternating light and dark patterns of the folds will better mimic the appearance of real colon tissue in colonoscopy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "401d39d54b794509891e210f6df79223",
      "be25c08b3aac431d9a8df50368fe3224",
      "4f5f79a8cf8a43ff8ae1d1b80989314f",
      "673ac709207649ad9e1633b1bc9bb434",
      "627f07872c564d45b9c42f15ab89a89a",
      "42f11bc1c5cc4ac6a2d5e19ee46490c0",
      "43d71c705f4b40988a8ac5bae829a22c",
      "64d3bb5938874b50966343e72a0c5786",
      "df78f88a8d4842cf954ab2eadc1da84a",
      "0664e7b4b4b4417a93d79691be16d955",
      "f5a720091bd34ed9b9969a16e9644684",
      "943d203087d441eb8eaafd813c0896a8",
      "4211a807a74d4804926f8ed127168587",
      "8f50a24ad9564805802a625b29b18f06",
      "a107cadc9ff747649096429078999943",
      "1a66f5f49bf747d6b7c59196ca633260",
      "91fce86608ea44f696e871f4d0d3da70",
      "0d1f02bb09114d1eb135bac1888bb028",
      "2f5da7c5272745cebaa226c50a9c8100",
      "768d7ded1129413c8d66c9b39afc6562",
      "2a441fda17f54fd8a82d9606fb13a2dd",
      "c93adce7dd7f4a9e912762237385c518"
     ]
    },
    "executionInfo": {
     "elapsed": 17227,
     "status": "error",
     "timestamp": 1741019017862,
     "user": {
      "displayName": "Jorge Lobo",
      "userId": "16086058243023786201"
     },
     "user_tz": 0
    },
    "id": "E2LjcuzBzvqY",
    "outputId": "026b87d0-461e-46e1-e5d1-03de91fa9e93"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# Colon Polyp Detection - Synthetic Data Generation and ML Model\n",
    "# Google Colab Notebook\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create directories for saving images\n",
    "os.makedirs('synthetic_colon_data/images', exist_ok=True)\n",
    "os.makedirs('synthetic_colon_data/masks', exist_ok=True)\n",
    "\n",
    "# Part 1: Enhanced Synthetic Colon Image Generation\n",
    "# ---------------------------------------\n",
    "\n",
    "def generate_colon_background(img_size=256, noise_factor=0.1):\n",
    "    \"\"\"Generate a synthetic colon background with a pinkish color and darker center.\"\"\"\n",
    "    # Base pink color for colon tissue\n",
    "    base_color = np.array([210, 140, 140])  # Pinkish color\n",
    "\n",
    "    # Create base image\n",
    "    img = np.ones((img_size, img_size, 3))\n",
    "\n",
    "    # Add radial gradient for tube-like appearance with darker center\n",
    "    y, x = np.ogrid[:img_size, :img_size]\n",
    "    center = img_size // 2\n",
    "    dist_from_center = np.sqrt((x - center)**2 + (y - center)**2)\n",
    "\n",
    "    # Normalize to [0, 1]\n",
    "    dist_from_center = dist_from_center / (np.sqrt(2) * center)\n",
    "\n",
    "    # Make center darker - add stronger vignetting effect\n",
    "    for c in range(3):\n",
    "        # More dramatic darkening in the center\n",
    "        img[:, :, c] = base_color[c] / 255.0 * (0.6 + 0.4 * dist_from_center)\n",
    "\n",
    "    # Add noise for texture\n",
    "    noise = np.random.randn(img_size, img_size, 3) * noise_factor\n",
    "    img += noise\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def add_colon_folds(img, num_folds=6, fold_width_range=(8, 15)):\n",
    "    \"\"\"Add concentric rings/folds to the colon image with more contrast.\"\"\"\n",
    "    img_size = img.shape[0]\n",
    "    center = img_size // 2\n",
    "\n",
    "    # Convert to PIL for drawing\n",
    "    pil_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    # Draw concentric circles for colon folds with alternating brightness\n",
    "    for i in range(1, num_folds + 1):\n",
    "        radius = (img_size // (num_folds + 2)) * i\n",
    "\n",
    "        # Add slight randomness to fold placement\n",
    "        radius += random.randint(-5, 5)\n",
    "\n",
    "        # Alternating fold brightness for more contrast\n",
    "        if i % 2 == 0:\n",
    "            # Lighter fold\n",
    "            fold_color = (200, 130, 130)  # Lighter pink\n",
    "            fold_width = random.randint(fold_width_range[0], fold_width_range[1])\n",
    "        else:\n",
    "            # Darker fold\n",
    "            fold_color = (170, 100, 100)  # Darker pink\n",
    "            fold_width = random.randint(fold_width_range[0] + 2, fold_width_range[1] + 2)  # Slightly wider\n",
    "\n",
    "        # Draw with varying opacity based on distance from center for perspective\n",
    "        opacity_factor = 0.7 + 0.3 * (i / num_folds)  # More pronounced outer folds\n",
    "        adjusted_color = tuple(int(c * opacity_factor) for c in fold_color)\n",
    "\n",
    "        # Draw squished ellipses for perspective (more squished near center)\n",
    "        squish_factor = 0.6 + 0.2 * (i / num_folds)  # More circular as we move outward\n",
    "        ellipse_bounds = [\n",
    "            center - radius,\n",
    "            center - radius * squish_factor,\n",
    "            center + radius,\n",
    "            center + radius * squish_factor\n",
    "        ]\n",
    "\n",
    "        # Draw the fold\n",
    "        draw.ellipse(ellipse_bounds, outline=adjusted_color, width=fold_width)\n",
    "\n",
    "        # Add highlight effect on the upper part of some folds for depth\n",
    "        if i % 2 == 0 and i > 1:\n",
    "            highlight_bounds = [\n",
    "                center - radius + fold_width//2,\n",
    "                center - radius * squish_factor + fold_width//2,\n",
    "                center + radius - fold_width//2,\n",
    "                center - radius * squish_factor//2\n",
    "            ]\n",
    "            # Partial highlight arc\n",
    "            draw.arc(highlight_bounds, 180, 360, fill=(230, 170, 170), width=fold_width//2)\n",
    "\n",
    "    # Add a dark central area to simulate depth\n",
    "    central_radius = img_size // (num_folds + 2)\n",
    "    central_ellipse = [\n",
    "        center - central_radius,\n",
    "        center - central_radius * 0.6,\n",
    "        center + central_radius,\n",
    "        center + central_radius * 0.6\n",
    "    ]\n",
    "    # Draw dark central area with gradient\n",
    "    for r in range(central_radius, 0, -2):\n",
    "        darkness = 0.6 - (r / central_radius) * 0.4  # Darker toward center\n",
    "        dark_color = tuple(int(c * (1-darkness)) for c in (170, 100, 100))\n",
    "        inner_ellipse = [\n",
    "            center - r,\n",
    "            center - r * 0.6,\n",
    "            center + r,\n",
    "            center + r * 0.6\n",
    "        ]\n",
    "        draw.ellipse(inner_ellipse, fill=dark_color, outline=None)\n",
    "\n",
    "    # Convert back to numpy\n",
    "    img = np.array(pil_img) / 255.0\n",
    "    return img\n",
    "\n",
    "def generate_polyp(img_size=256, min_radius=10, max_radius=30):\n",
    "    \"\"\"Generate a polyp mask and the polyp appearance.\"\"\"\n",
    "    mask = np.zeros((img_size, img_size), dtype=np.uint8)\n",
    "\n",
    "    # Random position for the polyp\n",
    "    center_x = random.randint(img_size // 4, 3 * img_size // 4)\n",
    "    center_y = random.randint(img_size // 4, 3 * img_size // 4)\n",
    "\n",
    "    # Random radius for the polyp\n",
    "    radius = random.randint(min_radius, max_radius)\n",
    "\n",
    "    # Create a PIL image for drawing\n",
    "    mask_img = Image.fromarray(mask)\n",
    "    draw = ImageDraw.Draw(mask_img)\n",
    "\n",
    "    # Draw an ellipse for the polyp (slightly irregular)\n",
    "    squish_factor = random.uniform(0.7, 1.0)\n",
    "    ellipse_bounds = [\n",
    "        center_x - radius,\n",
    "        center_y - radius * squish_factor,\n",
    "        center_x + radius,\n",
    "        center_y + radius * squish_factor\n",
    "    ]\n",
    "    draw.ellipse(ellipse_bounds, fill=1)\n",
    "\n",
    "    # Add irregularity to some polyps (about 40% of polyps)\n",
    "    if random.random() < 0.4:\n",
    "        # Add a random \"bump\" to the polyp\n",
    "        bump_angle = random.uniform(0, 2 * np.pi)\n",
    "        bump_distance = radius * 0.7\n",
    "        bump_size = radius * random.uniform(0.3, 0.5)\n",
    "\n",
    "        bump_x = center_x + bump_distance * np.cos(bump_angle)\n",
    "        bump_y = center_y + bump_distance * np.sin(bump_angle)\n",
    "\n",
    "        bump_bounds = [\n",
    "            bump_x - bump_size,\n",
    "            bump_y - bump_size,\n",
    "            bump_x + bump_size,\n",
    "            bump_y + bump_size\n",
    "        ]\n",
    "        draw.ellipse(bump_bounds, fill=1)\n",
    "\n",
    "    # Convert back to numpy\n",
    "    mask = np.array(mask_img)\n",
    "\n",
    "    # For polyp appearance (reddish/darker color with texture)\n",
    "    polyp_color = np.array([180, 100, 100]) / 255.0  # Darker red\n",
    "\n",
    "    # Make some polyps more pinkish (variety)\n",
    "    if random.random() < 0.3:\n",
    "        polyp_color = np.array([220, 120, 120]) / 255.0  # More pinkish\n",
    "\n",
    "    # Add slight texture variation\n",
    "    polyp_texture = generate_polyp_texture(mask, polyp_color)\n",
    "\n",
    "    return mask, polyp_texture\n",
    "\n",
    "def generate_polyp_texture(mask, base_color):\n",
    "    \"\"\"Generate texture for the polyp with more realistic appearance.\"\"\"\n",
    "    img_size = mask.shape[0]\n",
    "    texture = np.zeros((img_size, img_size, 3))\n",
    "\n",
    "    # Find the center and radius of the polyp\n",
    "    y_indices, x_indices = np.where(mask > 0)\n",
    "    if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "        return texture\n",
    "\n",
    "    center_y = int(np.mean(y_indices))\n",
    "    center_x = int(np.mean(x_indices))\n",
    "\n",
    "    # Estimate radius as distance to furthest point\n",
    "    max_dist = 0\n",
    "    for y, x in zip(y_indices, x_indices):\n",
    "        dist = np.sqrt((y - center_y)**2 + (x - center_x)**2)\n",
    "        max_dist = max(max_dist, dist)\n",
    "\n",
    "    # Create a distance map from center for shading\n",
    "    y, x = np.ogrid[:img_size, :img_size]\n",
    "    dist_from_center = np.sqrt((y - center_y)**2 + (x - center_x)**2)\n",
    "\n",
    "    # Normalize distances for shading (0 at center, 1 at edge)\n",
    "    normalized_dist = np.zeros_like(dist_from_center)\n",
    "    mask_indices = mask > 0\n",
    "    if np.any(mask_indices):\n",
    "        normalized_dist[mask_indices] = dist_from_center[mask_indices] / max_dist\n",
    "\n",
    "    # Create highlights and shadows\n",
    "    highlight_dir = random.uniform(0, 2 * np.pi)  # Random direction for highlight\n",
    "    highlight_x = np.cos(highlight_dir)\n",
    "    highlight_y = np.sin(highlight_dir)\n",
    "\n",
    "    # Calculate highlight intensity based on direction\n",
    "    y_rel = (y - center_y) / (max_dist + 1e-6)\n",
    "    x_rel = (x - center_x) / (max_dist + 1e-6)\n",
    "    directional_component = x_rel * highlight_x + y_rel * highlight_y\n",
    "\n",
    "    # Create texture with highlight and shadow\n",
    "    for c in range(3):\n",
    "        # Base color\n",
    "        color_map = np.ones((img_size, img_size)) * base_color[c]\n",
    "\n",
    "        # Add radial shading (darker toward edges)\n",
    "        edge_darkening = 0.3 * normalized_dist  # Darken up to 30% at edges\n",
    "\n",
    "        # Add directional highlight (brighten in highlight direction, darken in opposite)\n",
    "        highlight = 0.2 * directional_component  # +/- 20% variation based on direction\n",
    "\n",
    "        # Apply both effects where the mask is active\n",
    "        color_map[mask > 0] = color_map[mask > 0] * (1 - edge_darkening[mask > 0] + highlight[mask > 0])\n",
    "\n",
    "        # Add some random texture variation\n",
    "        noise = np.random.randn(img_size, img_size) * 0.05\n",
    "        color_map[mask > 0] += noise[mask > 0]\n",
    "\n",
    "        # Ensure values are in valid range\n",
    "        color_map = np.clip(color_map, 0, 1)\n",
    "\n",
    "        # Apply to texture\n",
    "        texture[:, :, c] = mask * color_map\n",
    "\n",
    "    return texture\n",
    "\n",
    "def add_polyp_to_image(img, mask, polyp_texture):\n",
    "    \"\"\"Add a polyp to the colon image with better blending.\"\"\"\n",
    "    # Blend the polyp with the background image\n",
    "    result = img.copy()\n",
    "\n",
    "    # Create a blurred edge mask for better blending\n",
    "    y_indices, x_indices = np.where(mask > 0)\n",
    "    if len(y_indices) == 0:\n",
    "        return result\n",
    "\n",
    "    # Find polyp center and max radius\n",
    "    center_y = int(np.mean(y_indices))\n",
    "    center_x = int(np.mean(x_indices))\n",
    "\n",
    "    # Calculate distances for all polyp pixels\n",
    "    distances = np.sqrt((y_indices - center_y)**2 + (x_indices - center_x)**2)\n",
    "    max_dist = np.max(distances)\n",
    "\n",
    "    # Create a soft edge mask with blur\n",
    "    soft_mask = mask.copy().astype(float)\n",
    "\n",
    "    # For each positive pixel in the mask\n",
    "    for y, x, dist in zip(y_indices, x_indices, distances):\n",
    "        # If we're near the edge (within 15% of max radius from edge)\n",
    "        edge_ratio = dist / max_dist\n",
    "        if edge_ratio > 0.85:\n",
    "            # Calculate opacity based on distance to edge (1 at core, 0 at edge)\n",
    "            fade_factor = 1.0 - ((edge_ratio - 0.85) / 0.15)\n",
    "            soft_mask[y, x] = fade_factor\n",
    "\n",
    "    # Apply the soft mask for blending\n",
    "    for c in range(3):\n",
    "        result[:, :, c] = result[:, :, c] * (1 - soft_mask) + polyp_texture[:, :, c]\n",
    "\n",
    "    # Ensure values are valid\n",
    "    result = np.clip(result, 0, 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_dataset(num_images=500, img_size=256):\n",
    "    \"\"\"Generate a synthetic dataset of colon images with and without polyps.\"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for i in tqdm(range(num_images), desc=\"Generating synthetic data\"):\n",
    "        # Generate background\n",
    "        img = generate_colon_background(img_size)\n",
    "        img = add_colon_folds(img)\n",
    "\n",
    "        # With 70% probability, add a polyp\n",
    "        has_polyp = random.random() < 0.7\n",
    "\n",
    "        if has_polyp:\n",
    "            # Generate between 1 and 3 polyps\n",
    "            num_polyps = random.randint(1, 3)\n",
    "            combined_mask = np.zeros((img_size, img_size))\n",
    "\n",
    "            for _ in range(num_polyps):\n",
    "                polyp_mask, polyp_texture = generate_polyp(img_size)\n",
    "                img = add_polyp_to_image(img, polyp_mask, polyp_texture)\n",
    "                combined_mask = np.maximum(combined_mask, polyp_mask)\n",
    "        else:\n",
    "            combined_mask = np.zeros((img_size, img_size))\n",
    "\n",
    "        # Save the images and masks\n",
    "        img_array = (img * 255).astype(np.uint8)\n",
    "        mask_array = (combined_mask * 255).astype(np.uint8)\n",
    "\n",
    "        # Save images to disk\n",
    "        Image.fromarray(img_array).save(f'synthetic_colon_data/images/{i:04d}.png')\n",
    "        Image.fromarray(mask_array).save(f'synthetic_colon_data/masks/{i:04d}.png')\n",
    "\n",
    "        # Keep in memory for visualization\n",
    "        images.append(img)\n",
    "        masks.append(combined_mask)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "# Generate the dataset\n",
    "images, masks = generate_dataset(num_images=100)  # Reduced for notebook demonstration\n",
    "\n",
    "# Visualize some examples\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "for i in range(3):\n",
    "    idx = random.randint(0, len(images) - 1)\n",
    "    axes[i, 0].imshow(images[idx])\n",
    "    axes[i, 0].set_title(f\"Image {idx}\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    axes[i, 1].imshow(masks[idx], cmap='gray')\n",
    "    axes[i, 1].set_title(f\"Mask {idx}\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Part 2: PyTorch Dataset and DataLoader\n",
    "# -------------------------------------\n",
    "\n",
    "class ColonPolypsDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None, mask_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.images = sorted(os.listdir(img_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert to grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        else:\n",
    "            # Normalize mask to [0, 1]\n",
    "            mask = np.array(mask) / 255.0\n",
    "            mask = torch.from_numpy(mask).float().unsqueeze(0)  # Add channel dim\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_val_dataset = ColonPolypsDataset(\n",
    "    img_dir='synthetic_colon_data/images',\n",
    "    mask_dir='synthetic_colon_data/masks',\n",
    "    transform=None,  # Will apply transforms after splitting\n",
    "    mask_transform=None\n",
    ")\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_size = int(0.8 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "# Apply transforms to the split datasets\n",
    "class TransformedSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None, mask_transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, mask = self.subset[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        else:\n",
    "            # Normalize mask to [0, 1]\n",
    "            mask = np.array(mask) / 255.0\n",
    "            mask = torch.from_numpy(mask).float().unsqueeze(0)  # Add channel dim\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = TransformedSubset(train_dataset, train_transform, mask_transform)\n",
    "val_dataset = TransformedSubset(val_dataset, val_transform, mask_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Part 3: Model Definition (U-Net for segmentation)\n",
    "# -----------------------------------------------\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        # Padding if needed\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = nn.functional.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                              diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        logits = self.outc(x)\n",
    "        return self.sigmoid(logits)\n",
    "\n",
    "# Initialize the model\n",
    "model = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)\n",
    "\n",
    "# Define loss function\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # BCE Loss\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "\n",
    "        # Dice Loss\n",
    "        inputs_flat = inputs.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs_flat * targets_flat).sum()\n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (inputs_flat.sum() + targets_flat.sum() + smooth)\n",
    "\n",
    "        # Combined loss (BCE + Dice)\n",
    "        return bce_loss + dice_loss\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "# Part 4: Training Loop\n",
    "# -------------------\n",
    "\n",
    "def dice_coefficient(y_pred, y_true, smooth=1e-6):\n",
    "    \"\"\"Calculate Dice coefficient for evaluation.\"\"\"\n",
    "    y_pred = y_pred.view(-1)\n",
    "    y_true = y_true.view(-1)\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    return (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    \"\"\"Train the segmentation model.\"\"\"\n",
    "    best_val_dice = 0.0\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_dice': [],\n",
    "        'val_dice': []\n",
    "    }\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 10\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "\n",
    "        for inputs, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            # Calculate Dice coefficient\n",
    "            dice = dice_coefficient(outputs, masks)\n",
    "            train_dice += dice.item()\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Average training statistics\n",
    "        train_loss /= len(train_loader)\n",
    "        train_dice /= len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                inputs = inputs.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "                # Calculate Dice coefficient\n",
    "                dice = dice_coefficient(outputs, masks)\n",
    "                val_dice += dice.item()\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average validation statistics\n",
    "        val_loss /= len(val_loader)\n",
    "        val_dice /= len(val_loader)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Save statistics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_dice'].append(train_dice)\n",
    "        history['val_dice'].append(val_dice)\n",
    "\n",
    "        # Print statistics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_dice > best_val_dice:\n",
    "            best_val_dice = val_dice\n",
    "            torch.save(model.state_dict(), 'best_polyp_segmentation_model.pth')\n",
    "            print(f\"Saved new best model with Dice: {best_val_dice:.4f}\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Best validation Dice coefficient: {best_val_dice:.4f}\")\n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_dice'], label='Train Dice')\n",
    "plt.plot(history['val_dice'], label='Validation Dice')\n",
    "plt.title('Dice Coefficient Over Time')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice Coefficient')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Part 5: Model Evaluation and Visualization\n",
    "# ----------------------------------------\n",
    "# Part 5: Model Evaluation and Visualization\n",
    "# ----------------------------------------\n",
    "\n",
    "def visualize_predictions(model, dataloader, num_samples=3):\n",
    "    \"\"\"Visualize some predictions from the model.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get a batch from the dataloader\n",
    "    dataiter = iter(dataloader)\n",
    "    inputs, masks = next(dataiter)\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(inputs)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    inputs = inputs.cpu().numpy()\n",
    "    masks = masks.cpu().numpy()\n",
    "    predictions = predictions.cpu().numpy()\n",
    "\n",
    "    # Visualize a few examples\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Original image (denormalize)\n",
    "        img = inputs[i].transpose(1, 2, 0)\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        # Ground truth mask\n",
    "        mask = masks[i, 0]\n",
    "\n",
    "        # Predicted mask\n",
    "        pred = predictions[i, 0]\n",
    "\n",
    "        # Display\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth Mask')\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        axes[i, 2].imshow(pred, cmap='gray')\n",
    "        axes[i, 2].set_title('Predicted Mask')\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_polyp_segmentation_model.pth'))\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_predictions(model, val_loader, num_samples=5)\n",
    "\n",
    "# Part 6: Performance Evaluation\n",
    "# ----------------------------\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"Evaluate the model on the given dataloader.\"\"\"\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in tqdm(dataloader, desc=\"Evaluating model\"):\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate Dice coefficient for each image\n",
    "            for i in range(outputs.size(0)):\n",
    "                dice = dice_coefficient(outputs[i], masks[i])\n",
    "                dice_scores.append(dice.item())\n",
    "\n",
    "    # Calculate statistics\n",
    "    avg_dice = np.mean(dice_scores)\n",
    "    std_dice = np.std(dice_scores)\n",
    "\n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"Average Dice Coefficient: {avg_dice:.4f} ± {std_dice:.4f}\")\n",
    "\n",
    "    # Plot histogram of dice scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(dice_scores, bins=20, alpha=0.7)\n",
    "    plt.axvline(avg_dice, color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(avg_dice+0.02, plt.ylim()[1]*0.9, f'Mean: {avg_dice:.4f}', color='r')\n",
    "    plt.title('Distribution of Dice Scores')\n",
    "    plt.xlabel('Dice Coefficient')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    return dice_scores\n",
    "\n",
    "# Evaluate the model\n",
    "dice_scores = evaluate_model(model, val_loader)\n",
    "\n",
    "# Part 7: Function for Making Predictions on New Images\n",
    "# --------------------------------------------------\n",
    "\n",
    "def predict_polyps(model, image_path, output_path=None):\n",
    "    \"\"\"Predict polyps on a new image.\"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_size = image.size\n",
    "\n",
    "    # Preprocess\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor)\n",
    "        prediction = prediction.cpu().squeeze().numpy()\n",
    "\n",
    "    # Resize prediction back to original size\n",
    "    prediction_img = Image.fromarray((prediction * 255).astype(np.uint8))\n",
    "    prediction_img = prediction_img.resize(original_size, Image.NEAREST)\n",
    "\n",
    "    # Convert original image to numpy for visualization\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # Create overlay\n",
    "    prediction_np = np.array(prediction_img)\n",
    "\n",
    "    # Create RGB mask with red color for visualization\n",
    "    overlay = np.zeros_like(image_np)\n",
    "    overlay[prediction_np > 127, 0] = 255  # Red channel\n",
    "\n",
    "    # Blend with original image\n",
    "    alpha = 0.5\n",
    "    blended = (image_np * (1 - alpha) + overlay * alpha).astype(np.uint8)\n",
    "\n",
    "    # Visualize\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(prediction_np, cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(blended)\n",
    "    plt.title('Overlay')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save results if requested\n",
    "    if output_path:\n",
    "        # Save the blended image\n",
    "        Image.fromarray(blended).save(output_path)\n",
    "        print(f\"Saved prediction to {output_path}\")\n",
    "\n",
    "    return prediction_np\n",
    "\n",
    "# Generate a new test image\n",
    "test_img = generate_colon_background()\n",
    "test_img = add_colon_folds(test_img)\n",
    "\n",
    "# Add a polyp\n",
    "mask, polyp_texture = generate_polyp()\n",
    "test_img = add_polyp_to_image(test_img, mask, polyp_texture)\n",
    "\n",
    "# Save the test image\n",
    "test_img_path = 'test_colon_image.png'\n",
    "Image.fromarray((test_img * 255).astype(np.uint8)).save(test_img_path)\n",
    "\n",
    "# Predict on the test image\n",
    "prediction = predict_polyps(model, test_img_path, 'test_prediction.png')\n",
    "\n",
    "# Conclusion\n",
    "print(\"Training and Evaluation Complete!\")\n",
    "print(\"The notebook demonstrated:\")\n",
    "print(\"1. Generation of synthetic colon images with polyps\")\n",
    "print(\"2. Building and training a U-Net model for polyp detection\")\n",
    "print(\"3. Evaluating model performance\")\n",
    "print(\"4. Making predictions on new images\")\n",
    "print(\"\\nKey takeaways:\")\n",
    "print(\"- The model was trained on synthetic data, which is helpful for initial development\")\n",
    "print(\"- For real-world applications, this should be adapted to use real medical images\")\n",
    "print(\"- The U-Net architecture worked well for polyp segmentation\")\n",
    "print(\"- Data augmentation could further improve performance\")\n",
    "\n",
    "# Improvements for real-world application (for reference)\n",
    "\"\"\"\n",
    "If adapting this notebook for real medical images, consider:\n",
    "1. Using transfer learning from a pretrained model\n",
    "2. Implementing more extensive data augmentation\n",
    "3. Adding more evaluation metrics (precision, recall, etc.)\n",
    "4. Implementing post-processing for better segmentation\n",
    "5. Using more sophisticated architectures (DeepLabV3+, etc.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmPsY7_Z0G7H"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1741016847984,
     "user": {
      "displayName": "Jorge Lobo",
      "userId": "16086058243023786201"
     },
     "user_tz": 0
    },
    "id": "lk_Klm9Kr6cO"
   },
   "outputs": [],
   "source": [
    "def generate_colon_background(img_size=256, noise_factor=0.1):\n",
    "    \"\"\"Generate a synthetic colon background with a pinkish color and darker center.\"\"\"\n",
    "    # Base pink color for colon tissue\n",
    "    base_color = np.array([210, 140, 140])  # Pinkish color\n",
    "\n",
    "    # Create base image\n",
    "    img = np.ones((img_size, img_size, 3))\n",
    "\n",
    "    # Add radial gradient for tube-like appearance with darker center\n",
    "    y, x = np.ogrid[:img_size, :img_size]\n",
    "    center = img_size // 2\n",
    "    dist_from_center = np.sqrt((x - center)**2 + (y - center)**2)\n",
    "\n",
    "    # Normalize to [0, 1]\n",
    "    dist_from_center = dist_from_center / (np.sqrt(2) * center)\n",
    "\n",
    "    # Make center darker - add stronger vignetting effect\n",
    "    for c in range(3):\n",
    "        # More dramatic darkening in the center\n",
    "        img[:, :, c] = base_color[c] / 255.0 * (0.6 + 0.4 * dist_from_center)\n",
    "\n",
    "    # Add noise for texture\n",
    "    noise = np.random.randn(img_size, img_size, 3) * noise_factor\n",
    "    img += noise\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def add_colon_folds(img, num_folds=6, fold_width_range=(8, 15)):\n",
    "    \"\"\"Add concentric rings/folds to the colon image with more contrast.\"\"\"\n",
    "    img_size = img.shape[0]\n",
    "    center = img_size // 2\n",
    "\n",
    "    # Convert to PIL for drawing\n",
    "    pil_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    # Draw concentric circles for colon folds with alternating brightness\n",
    "    for i in range(1, num_folds + 1):\n",
    "        radius = (img_size // (num_folds + 2)) * i\n",
    "\n",
    "        # Add slight randomness to fold placement\n",
    "        radius += random.randint(-5, 5)\n",
    "\n",
    "        # Alternating fold brightness for more contrast\n",
    "        if i % 2 == 0:\n",
    "            # Lighter fold\n",
    "            fold_color = (200, 130, 130)  # Lighter pink\n",
    "            fold_width = random.randint(fold_width_range[0], fold_width_range[1])\n",
    "        else:\n",
    "            # Darker fold\n",
    "            fold_color = (170, 100, 100)  # Darker pink\n",
    "            fold_width = random.randint(fold_width_range[0] + 2, fold_width_range[1] + 2)  # Slightly wider\n",
    "\n",
    "        # Draw with varying opacity based on distance from center for perspective\n",
    "        opacity_factor = 0.7 + 0.3 * (i / num_folds)  # More pronounced outer folds\n",
    "        adjusted_color = tuple(int(c * opacity_factor) for c in fold_color)\n",
    "\n",
    "        # Draw squished ellipses for perspective (more squished near center)\n",
    "        squish_factor = 0.6 + 0.2 * (i / num_folds)  # More circular as we move outward\n",
    "        ellipse_bounds = [\n",
    "            center - radius,\n",
    "            center - radius * squish_factor,\n",
    "            center + radius,\n",
    "            center + radius * squish_factor\n",
    "        ]\n",
    "\n",
    "        # Draw the fold\n",
    "        draw.ellipse(ellipse_bounds, outline=adjusted_color, width=fold_width)\n",
    "\n",
    "        # Add highlight effect on the upper part of some folds for depth\n",
    "        if i % 2 == 0 and i > 1:\n",
    "            highlight_bounds = [\n",
    "                center - radius + fold_width//2,\n",
    "                center - radius * squish_factor + fold_width//2,\n",
    "                center + radius - fold_width//2,\n",
    "                center - radius * squish_factor//2\n",
    "            ]\n",
    "            # Partial highlight arc\n",
    "            draw.arc(highlight_bounds, 180, 360, fill=(230, 170, 170), width=fold_width//2)\n",
    "\n",
    "    # Add a dark central area to simulate depth\n",
    "    central_radius = img_size // (num_folds + 2)\n",
    "    central_ellipse = [\n",
    "        center - central_radius,\n",
    "        center - central_radius * 0.6,\n",
    "        center + central_radius,\n",
    "        center + central_radius * 0.6\n",
    "    ]\n",
    "    # Draw dark central area with gradient\n",
    "    for r in range(central_radius, 0, -2):\n",
    "        darkness = 0.6 - (r / central_radius) * 0.4  # Darker toward center\n",
    "        dark_color = tuple(int(c * (1-darkness)) for c in (170, 100, 100))\n",
    "        inner_ellipse = [\n",
    "            center - r,\n",
    "            center - r * 0.6,\n",
    "            center + r,\n",
    "            center + r * 0.6\n",
    "        ]\n",
    "        draw.ellipse(inner_ellipse, fill=dark_color, outline=None)\n",
    "\n",
    "    # Convert back to numpy\n",
    "    img = np.array(pil_img) / 255.0\n",
    "    return img"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0664e7b4b4b4417a93d79691be16d955": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d1f02bb09114d1eb135bac1888bb028": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a66f5f49bf747d6b7c59196ca633260": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a441fda17f54fd8a82d9606fb13a2dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f5da7c5272745cebaa226c50a9c8100": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "401d39d54b794509891e210f6df79223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be25c08b3aac431d9a8df50368fe3224",
       "IPY_MODEL_4f5f79a8cf8a43ff8ae1d1b80989314f",
       "IPY_MODEL_673ac709207649ad9e1633b1bc9bb434"
      ],
      "layout": "IPY_MODEL_627f07872c564d45b9c42f15ab89a89a"
     }
    },
    "4211a807a74d4804926f8ed127168587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91fce86608ea44f696e871f4d0d3da70",
      "placeholder": "​",
      "style": "IPY_MODEL_0d1f02bb09114d1eb135bac1888bb028",
      "value": "Epoch 1/15 - Training:   0%"
     }
    },
    "42f11bc1c5cc4ac6a2d5e19ee46490c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43d71c705f4b40988a8ac5bae829a22c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f5f79a8cf8a43ff8ae1d1b80989314f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64d3bb5938874b50966343e72a0c5786",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df78f88a8d4842cf954ab2eadc1da84a",
      "value": 100
     }
    },
    "627f07872c564d45b9c42f15ab89a89a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64d3bb5938874b50966343e72a0c5786": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "673ac709207649ad9e1633b1bc9bb434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0664e7b4b4b4417a93d79691be16d955",
      "placeholder": "​",
      "style": "IPY_MODEL_f5a720091bd34ed9b9969a16e9644684",
      "value": " 100/100 [00:03&lt;00:00, 27.14it/s]"
     }
    },
    "768d7ded1129413c8d66c9b39afc6562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f50a24ad9564805802a625b29b18f06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f5da7c5272745cebaa226c50a9c8100",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_768d7ded1129413c8d66c9b39afc6562",
      "value": 0
     }
    },
    "91fce86608ea44f696e871f4d0d3da70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "943d203087d441eb8eaafd813c0896a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4211a807a74d4804926f8ed127168587",
       "IPY_MODEL_8f50a24ad9564805802a625b29b18f06",
       "IPY_MODEL_a107cadc9ff747649096429078999943"
      ],
      "layout": "IPY_MODEL_1a66f5f49bf747d6b7c59196ca633260"
     }
    },
    "a107cadc9ff747649096429078999943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a441fda17f54fd8a82d9606fb13a2dd",
      "placeholder": "​",
      "style": "IPY_MODEL_c93adce7dd7f4a9e912762237385c518",
      "value": " 0/10 [00:00&lt;?, ?it/s]"
     }
    },
    "be25c08b3aac431d9a8df50368fe3224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42f11bc1c5cc4ac6a2d5e19ee46490c0",
      "placeholder": "​",
      "style": "IPY_MODEL_43d71c705f4b40988a8ac5bae829a22c",
      "value": "Generating synthetic data: 100%"
     }
    },
    "c93adce7dd7f4a9e912762237385c518": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df78f88a8d4842cf954ab2eadc1da84a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5a720091bd34ed9b9969a16e9644684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
