# -*- coding: utf-8 -*-
"""Qadence - Sagar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19FCerwSJnemif_CO1eh-pkWNk7lbYa9u
"""

import os
import itertools as it
import csv
import random
import math

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from PIL import Image, ImageDraw
from tqdm import tqdm

from qadence import (
    chain, kron, QuantumCircuit, run,
    H, X, MCRY, Z, RY, RX, CNOT,
    QNN, VariationalParameter, FeatureParameter, hea
)

from qadence.draw import display

import torch
from torch import tensor
from torch.optim import Adam

from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.model_selection import train_test_split

"""## Generate training images
This code does all the following things:
- Creates images with and without ellipses.
- Saves the images arrays (.npy files).
- Saves the images (.jpg files).
- Saves a label files (labels.csv) indicating whether an image contains an ellipse (1) or not (0).
"""

# Constants
IMAGE_SIZE = 256 # 8x8 pixels
NUM_IMAGES = 512  # Number of images to generate
OUTPUT_DIR = "pixel_art_dataset_2"  # Output directory
LABELS_FILE = os.path.join(OUTPUT_DIR, "labels.csv")  # Labels file path
GRAYSCALE_LEVELS = 8  # Number of grayscale levels

# Create output directory if it doesn't exist
os.makedirs(OUTPUT_DIR, exist_ok=True)

def create_smooth_gradient_background(size):
    """Create a smooth random gradient background."""
    corners = np.random.randint(0, GRAYSCALE_LEVELS, size=4) * (255 // (GRAYSCALE_LEVELS - 1))
    y, x = np.mgrid[0:size, 0:size] / (size - 1)
    top = corners[0] * (1 - x) + corners[1] * x
    bottom = corners[2] * (1 - x) + corners[3] * x
    gradient = top * (1 - y) + bottom * y
    return np.round(gradient).astype(np.uint8)

def add_ellipse(img_array, size):
    """Add an ellipse to the image."""
    temp_img = Image.fromarray(img_array, 'L')
    draw = ImageDraw.Draw(temp_img)
    x0, y0 = random.randint(0, size-3), random.randint(0, size-3)
    x1, y1 = x0 + random.randint(2, size//2), y0 + random.randint(2, size//2)
    fill_value = random.randint(0, GRAYSCALE_LEVELS-1) * (255 // (GRAYSCALE_LEVELS - 1))
    draw.ellipse([x0, y0, x1, y1], fill=fill_value)
    return np.array(temp_img)

def create_image(has_ellipse):
    img_array = create_smooth_gradient_background(IMAGE_SIZE)
    if has_ellipse:
        img_array = add_ellipse(img_array, IMAGE_SIZE)
    return img_array

dataset = []

for i in tqdm(range(NUM_IMAGES)):
    has_ellipse = random.random() < 0.5  # 50% chance
    img_array = create_image(has_ellipse)

    dataset.append({
        'image': img_array,
        'label': has_ellipse,
    })
    
    if dataset[i]['label'] == True:
        save_path = os.path.join(os.getcwd(), '..', 'dataset', 'temp', 'true')
        img = Image.fromarray(dataset[i]['image'])
        img.save(os.path.join(save_path, f"true_{i}.jpg"))
    else: 
        save_path = os.path.join(os.getcwd(), '..', 'dataset', 'temp', 'false')
        img = Image.fromarray(dataset[i]['image'])
        img.save(os.path.join(save_path, f"false_{i}.jpg"))
        

df_train = pd.DataFrame(dataset)

# Show an image
img_index = 6

fig, ax = plt.subplots()
ax.imshow(df_train.image[img_index], cmap='gray')
ax.set_title(f"Has polyp: {df_train.label[img_index]}")
del fig, ax

"""## Create QNN Circuit

### Feature circuit (image input)
"""

# Parameters to input the image into the circuit
# One variable per pixel, indexed by (row, col)
feature_params = {
    (row, col): FeatureParameter(f'x{row}{col}')
    for row in range(IMAGE_SIZE)
    for col in range(IMAGE_SIZE)
}

feature_params_list = list(feature_params.values())

# Parâmetros quânticos
qdim = math.floor(math.log2(IMAGE_SIZE))  # number of qubits to encode a row or a column
n_qubits = 2*qdim + 1  # 6 para posição (3 linha + 3 coluna) + 1 para intensidade
control_qubits = list(range(n_qubits-1))

def control_state(row: int, col: int):
    row_binary = f"{row:b}".rjust(qdim, '0')
    col_binary = f"{col:b}".rjust(qdim, '0')
    state = row_binary + col_binary
    return state

ops_feature = [kron(H(i) for i in range(n_qubits - 1))]  # Hadamard para posição

for (row, col), parameter in feature_params.items():
    rotation_gate = kron(MCRY(control_qubits, n_qubits - 1, parameter * np.pi))

    cstate = control_state(row, col)
    qubits_to_flip = [i for i, x in enumerate(cstate) if x == '1']

    if qubits_to_flip:
        ops_feature.append(kron(X(i) for i in qubits_to_flip))

    ops_feature.append(rotation_gate)

    if qubits_to_flip:
        ops_feature.append(kron(X(i) for i in qubits_to_flip))

chain_feature = chain(*ops_feature)
qc_feature = QuantumCircuit(n_qubits, chain_feature)
# display(qc_feature)

"""### Variational circuit (trainable layers)"""

depth = 4
qc_ansatz = hea(n_qubits, depth)
# display(qc_ansatz)

"""### Observable (circuit output)"""

obs_parameters = [VariationalParameter(f'z{i}') for i in range(n_qubits)]
observable = sum(obs_parameters[i] * Z(i) for i in range(n_qubits)) / n_qubits

ops_all = chain(*qc_feature, qc_ansatz)
qc = QuantumCircuit(n_qubits, ops_all)
model = QNN(qc, observable, inputs=feature_params_list)

"""## Training the circuit

### Prepare input data
"""

img_train = df_train.image / 255*np.pi
y_train = torch.tensor(np.array(df_train.label), dtype=torch.float64) * 2 - 1

input_dict_train = {
    feature.name: torch.tensor([img[i, j] for img in img_train], dtype=torch.float64)
    for (i, j), feature in feature_params.items()
}

"""### Define loss function"""

criterion = torch.nn.SoftMarginLoss()  # SoftMarginLoss is advised for data classification

def loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -> torch.Tensor:
    """Loss function encoding the problem to solve."""
    # Equation loss
    model_output = model.expectation(values=input_dict_train)

    loss = criterion(model_output.squeeze(), y_train)

    return loss

"""### Run optimization"""

optimizer = torch.optim.Adam(model.parameters(), lr=0.1)
n_epochs = 1000

for epoch in range(n_epochs):
    optimizer.zero_grad()
    loss = loss_fn(model, input_dict_train)
    loss.backward()
    optimizer.step()

    if epoch % 25 == 0:
        print(f"{epoch=}, Loss: {loss.item():.4f}")

loss

"""## Evaluation

### Generate test data
"""

dataset_test = []

for i in tqdm(range(NUM_IMAGES)):
    has_ellipse = random.random() < 0.5  # 50% chance
    img_array = create_image(has_ellipse)

    dataset_test.append({
        'image': img_array,
        'label': has_ellipse,
    })

df_test = pd.DataFrame(dataset_test)

img_test = df_test.image / 255*np.pi
y_test = torch.tensor(np.array(df_test.label), dtype=torch.float64) * 2 - 1

input_dict_test = {
    feature.name: torch.tensor([img[i, j] for img in img_test], dtype=torch.float64)
    for (i, j), feature in feature_params.items()
}

y_pred = model.expectation(values=input_dict_test).squeeze()

from collections import defaultdict

@np.vectorize
def classify(circuit_output):
    return int(bool(circuit_output > 0))

test_values = classify(y_test.detach().numpy())
predicted_values = classify(y_pred.detach().numpy())

confusion_matrix = np.zeros((2, 2), dtype=int)
for predicted_value, test_value in zip(predicted_values, test_values):
    confusion_matrix[predicted_value, test_value] += 1

confusion_matrix

fig, ax = plt.subplots()

sns.heatmap(
    confusion_matrix / NUM_IMAGES,
    annot=True,
    fmt="%",
    cmap="Blues",
    ax=ax,
)

ax.set_xticklabels(["Real\n Negative", "Real\n Positive"])
ax.set_yticklabels(["Predicted\n Negative", "Predicted\n Positive"])

del fig, ax

